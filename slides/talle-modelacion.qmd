---
title: "Modelos matem√°ticos"
subtitle: "Una introducci√≥n con Python"
author: "Emmanuel Alcal√°"
institute: "ITESO"
format: 
  beamer: 
    aspectratio: 169
    navigation: horizontal
    theme: Madrid
    urlcolor: blue
    slide-level: 1
    # colortheme: UBCblue
    incremental: false
    section-titles: true
    include-in-header: 
      text: |
        \usepackage{fontspec}
        \usepackage{fontawesome5}
        \usepackage{amsmath}
        \usepackage{amsfonts}
        \usepackage{amssymb}
        \usepackage{graphicx}
        \usepackage{tikz}
        \usepackage{colortbl}
        \usetikzlibrary{arrows.meta, positioning}
        \setbeamercovered{transparent}
        \usefonttheme{professionalfonts}
        \definecolor{royalazure}{rgb}{0.0, 0.22, 0.66}
        \definecolor{UBCblue}{rgb}{0.04706, 0.13725, 0.26667}
        \setbeamertemplate{frametitle}[default][center]
        \setbeamercolor{title}{fg=gray!10}
        \setbeamerfont{title}{series=\bfseries}
        \usecolortheme[named=UBCblue]{structure}
jupyter: python3
---

# Bienvenida e introducci√≥n {.incremental}

## Presentaci√≥n

- Emmanuel Alcal√°: 
  * Dr. en Ciencias del Comportamiento en UDG.
  * Profesor asociado en ITESO desde el 2021: Teor√≠a de Juegos, Econometr√≠a, An√°lisis estad√≠stico multivariado (Maestr√≠a en Ciencia de Datos).
  * Desde 2024 Data Analyst en HP Inc.
  * 12 publicaciones cient√≠ficas en revistas indizadas.

---


Slides, datos y c√≥digo en Github: [Modelos matem√°ticos](https://github.com/jealcalat/Modelos-matematicos-CETIS).

## Programa general

::: {.latex}
\begin{table}[ht]
\centering
\label{tab:agenda-ajustada}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Hora} & \textbf{Duraci√≥n} & \textbf{Tema y Actividad Principal} \\ \hline
08:00 - 08:15 & 15 min & Bienvenida e Introducci√≥n \\ \hline
08:15 - 09:15 & 90 min & Secci√≥n 1: ¬øQu√© es la Modelaci√≥n Matem√°tica? \\ \hline
09:45 - 10:30 & 45 min & Secci√≥n 2: Tipos de Modelos Matem√°ticos \\ \hline
10:30 - 10:35 & 5 min  & Receso \\ \hline
10:35 - 11:00 & 25 min & Secci√≥n 3, Parte I: Instalaci√≥n de Herramientas y Ejercicios \\ \hline
11:00 - 12:00 & 60 min & Secci√≥n 3, Parte II: El Proceso de Modelaci√≥n \\ \hline
12:00 - 12:20 & 20 min & Receso Principal \\ \hline
12:20 - 13:20 & 60 min & Secci√≥n 4, Parte I: Fundamentos de Modelos probabil√≠sticos \\ \hline
13:20 - 13:25 & 5 min  & Receso \\ \hline
13:25 - 14:25 & 60 min & Secci√≥n 4, Parte II: Ajuste e Interpretaci√≥n \\ \hline
14:25 - 15:00 & 35 min & Cierre, Preguntas y Discusi√≥n Final \\ \hline
\end{tabular}
\end{table}
:::

---

# Secci√≥n 1: ¬øQu√© es la Modelaci√≥n Matem√°tica?

**Objetivo**: Establecer una base conceptual y filos√≥fica sobre qu√© es un modelo, por qu√© los usamos y cu√°les son sus limitaciones.

---

**Qu√© es un modelo**

* Nociones convencionales sobre el concepto de "modelo".

---

**Qu√© es un modelo**

- El modelo como abstracci√≥n simplificada de la realidad.

::: {.latex}
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.7\textwidth]{figuras/world-model-relationship.png}
  \caption{Relaciones entre realidad, modelo, interpretaci√≥n.}
  \label{fig:world-model-relationship}
\end{figure}
:::

---

- Analog√≠a: los modelos son como _mapas_.
  * Los mapas no son el territorio.
  * Preservan ciertas relaciones.
  * Son m√°s "simples".
  * Su utilidad no est√° en que sean detallados.

---

**Relaci√≥n entre complejidad, utilidad y precisi√≥n**

::: {.latex}
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.7\textwidth]{figuras/complexity-vs-accuracy-vs-usabiility.png}
  \caption{Cuanto m√°s preciso, m√°s complejo; cuanto m√°s complejo, menos √∫til.}
  \label{fig:mapa-vs-territorio}
\end{figure}
:::

---

## GPS como modelo: un mapa digital del mundo

- Fen√≥meno real:
  * Red de calles.
  * Topograf√≠a del terreno.
  * Estado del pavimento.
  * La ubicaci√≥n de √°rboles, edificios, casas.
  * Aspectos cambiantes (tr√°fico, construcciones, etc).

¬øQu√© aspectos retirar y abstraer para convertirlo en un (buen) modelo?

---

- Una aplicaci√≥n GPS no intenta replicar esa realidad. 
- Crea una abstracci√≥n, un modelo matem√°tico simplificado. 
- La clave est√° en la simplificaci√≥n deliberada: se omiten los detalles irrelevantes para el prop√≥sito de navegar.

--- 

## Abstracci√≥n: grafo ponderado

El modelo del GPS es, en esencia, un grafo ponderado: Las calles son aristas y las intersecciones los nodos. Los "pesos" de las aristas son variables (distancia, el l√≠mite de velocidad, el tiempo de viaje estimado) que se actualiza con datos en tiempo real.

::: {.latex}
\
\begin{table}[ht]
\centering
\begin{tabular}{|p{6cm}|p{7cm}|}
\hline
\textbf{Realidad (Compleja)} & \textbf{Modelo GPS (Abstracci√≥n)} \\ \hline
Calles con ancho, baches, m√∫ltiples carriles. & L√≠neas o arcos (vectores) en un grafo. \\ \hline
Intersecciones complejas con sem√°foros, se√±ales. & Nodos que conectan las l√≠neas. \\ \hline
Flujo de tr√°fico ca√≥tico y variable. & Atributos num√©ricos en las l√≠neas (ej. velocidad promedio, tiempo de recorrido estimado). \\ \hline
Edificios, parques, topograf√≠a. & Ignorados/presentados como pol√≠gonos sin impacto en los c√°lculos de la ruta. \\ \hline
\end{tabular}
\end{table}
:::

---

>**Todos los modelos son err√≥neos, pero algunos son √∫tiles** - George Box

El GPS como modelo fue construido con un prop√≥sito espec√≠fico:

- **Encontrar una ruta √≥ptima** de acuerdo a ciertas restricciones o par√°metros entre un punto *A* y un punto *B*.

- Para lograrlo, se ejecutan algoritmos como el de Dijkstra sobre el grafo simplificado (computacionalmente intratable si se ejecuta sobre el mundo real).

---

*¬øPor qu√© es un modelo *err√≥neo*? ¬øPor qu√© es √∫til?*

- Es err√≥neo por dise√±o: no contiene al detalle el terreno, tr√°fico, etc., por lo que las predicciones no son exactas sino **aproximadas**.
- Pero es √∫til porque sus **aproximaciones** son mejores que nada, y adem√°s aunque no prediga con exactitud el punto y tiempo de llegada, nos permite llegar siempre (aproximadamente cerca, aproximadamente a tiempo). Es m√°s, podr√≠amos predecir incluso el margen de error.

---

## Si ya tenemos la realidad ¬øpara qu√© sirve un modelo?

Si los modelos _no se supone que sean realistas y exactos_, ¬øpara qu√© sirven?

- Primero, para entender mejor alg√∫n aspecto del mundo (e.g., modelo de ADN).
- Segundo, para realizar predicciones sobre el mundo.
- Tercero, para probar una idea (que esa idea tiene una correspondencia con el mundo).

- ¬øEl modelo de GPS puede responder a esas preguntas?

--- 

**Actividad (15 min)**

::: {.nonincremental}

Formar equipos de $k$ tal que $n \bmod k = 0$. Elegir una app, objeto o representaci√≥n que usemos de forma cotidiana (que no sea un mapa/GPS) que pueda entenderse como un modelo. 

Discutir:

- ¬øQu√© sistema complejo de la realidad est√° representando o abstrayendo este modelo?
- ¬øCu√°l es su prop√≥sito principal? Es decir, ¬øpara qu√© fue dise√±ado y qu√© problema nos ayuda a resolver?
- ¬øQu√© simplifica o ignora deliberadamente de la realidad para poder ser √∫til?
- ¬øEn qu√© sentido es "incorrecto" o "impreciso"? ¬øCu√°les son sus limitaciones y en qu√© situaciones podr√≠a fallar?
:::

\rule{0.5\textwidth}{1pt}

---

**Contestando a la pregunta: ¬øqu√© es un modelo matem√°tico?**

::: {.nonincremental}

Una representaci√≥n **abstracta** y **simplificada** de un sistema o fen√≥meno expresada en t√©rminos de un lenguaje formal (matem√°tico). Su prop√≥sito es **entender, predecir** y/o **probar ideas de c√≥mo funciona el mundo**.

- Que sea simplificado no significa que sea _trivial_. Las matem√°ticas pueden ser demandantes.
- No pretende ser una r√©plica de la realidad, sino una representaci√≥n que captura ciertas relaciones e ignora otras.
- Qu√© ignorar y qu√© incluir requiere decisiones basadas en asunciones.
- Pueden mejorarse.
:::

---

#  Secci√≥n 2: Tipos de modelos matem√°ticos

**Objetivo**: Presentar un panorama de las distintas clases de modelos seg√∫n diferentes aspectos.

---

* El universo de los "modelos" es muy amplio.
* Incluye modelos f√≠sicos (ej. maqueta de un edificio, doble h√©lice del ADN) y modelos computacionales (ej. simulaci√≥n del clima).
* Nos centraremos en un tipo: los modelos matem√°ticos.
  * Estos usan el lenguaje de las matem√°ticas (ecuaciones, funciones, l√≥gica) para describir un sistema.
  * Hay sistemas tan complejos (ej. clima, din√°micas sociales) que es inviable describirlos con una sola ecuaci√≥n. En su lugar, se usan modelos de simulaci√≥n (como los basados en agentes) que aplican reglas matem√°ticas a miles de componentes individuales.
  * Los clasificamos en ejes o dicotom√≠as para entender su naturaleza y elegir las herramientas correctas.

---

### üé≤ Determin√≠stico vs. Estoc√°stico

::: {.nonincremental}

* **Determin√≠stico**: No incluye aleatoriedad. Con las mismas condiciones iniciales, el resultado es siempre el mismo.
    * *Ejemplo:* La ley de enfriamiento de Newton, $$T(t) = T_{a} + (T_{0} - T_{a})e^{-kt}$$.

* **Estoc√°stico (Probabil√≠stico)**: Incorpora incertidumbre. El resultado puede variar en cada ejecuci√≥n.
    * *Ejemplo:* Un modelo de caminata aleatoria para el precio de una acci√≥n.

:::

---

### üì∂ Discreto vs. Continuo

::: {.nonincremental}

* **Discreto**: El estado del sistema se eval√∫a en puntos o intervalos de tiempo espec√≠ficos (d√≠as, a√±os).
    * *Ejemplo:* Un modelo de crecimiento poblacional anual, $P_{n+1} = r \cdot P_n$.

* **Continuo**: El estado del sistema cambia constantemente en el tiempo, descrito por ecuaciones diferenciales.
    * *Ejemplo:* El decaimiento radioactivo, $$\frac{dN}{dt} = -\lambda N$$.

:::

---

### üî¨ Mecanicista vs. Emp√≠rico

::: {.nonincremental}

* **Mecanicista (Te√≥rico)**: Se basa en los mecanismos o primeros principios del fen√≥meno. Intenta explicar el **porqu√©**.
    * *Ejemplo:* Modelo de √≥rbitas planetarias basado en la Ley de Gravitaci√≥n Universal.

* **Emp√≠rico (Fenomenol√≥gico)**: Se basa en ajustar una funci√≥n a los datos observados, sin explicar el mecanismo. Describe el **qu√©**.
    * *Ejemplo:* Regresi√≥n que relaciona ventas de helados con la temperatura.

:::

---

### üìà Lineal vs. No Lineal

::: {.nonincremental}

* **Lineal**: Todas las relaciones entre variables son proporcionales (l√≠neas rectas).
    * *Ejemplo:* La Ley de Ohm en un circuito simple ($V=IR$).

* **No Lineal**: Al menos una relaci√≥n importante no es lineal. Son m√°s realistas para sistemas complejos.
    * *Ejemplo:* El modelo depredador-presa de Lotka-Volterra.
:::

---

::: {.nonincremental}

**Caso de estudio: crecimiento de una poblaci√≥n de conejos**

**Modelo 1: Discreto y Determin√≠stico**

**Idea:** La poblaci√≥n del pr√≥ximo a√±o es simplemente un 20% mayor que la de este a√±o.

**Modelo:** Una relaci√≥n de recurrencia simple.
$$P_{n+1} = 1.2 \cdot P_n$$

- $P$: Poblaci√≥n
- $n$: A√±o.
- $r$: Tasa de Crecimiento

**Clasificaci√≥n:**

* Discreto: Calculamos la poblaci√≥n en pasos anuales.
* Determin√≠stico: No hay aleatoriedad. El resultado es predecible.
* Mecanicista (simple): Se basa en una regla de reproducci√≥n.

:::

---

```{python}
#| echo: false
#| eval: true
#| fig-align: center

import numpy as np
import matplotlib.pyplot as plt

# Modelo 1: Discreto y Determin√≠stico
P0 = 10
r = 0.2
n_years = 20
P_discrete = [P0]
for _ in range(n_years):
    P_discrete.append(P_discrete[-1] * (1 + r))

years = np.arange(n_years + 1)

plt.style.use('seaborn-v0_8-whitegrid')
# Create figure with specific size first
fig = plt.figure(figsize=(5, 3.5))
ax = fig.add_subplot(111)
ax.plot(years, P_discrete, 'o-', label='Modelo Discreto Determin√≠stico', color='skyblue')
ax.set_title("Crecimiento Exponencial Simple")
ax.set_xlabel("A√±os")
ax.set_ylabel("Poblaci√≥n de Conejos")
ax.legend()
plt.tight_layout()  # Adjust layout to prevent label clipping
plt.show()
```

---

- Predicci√≥n sencilla: Si en el a√±o 0 comenzamos con 20 conejos, ¬øcu√°ntos tendremos en 20 a√±os?

```{python}
#| echo: true
#| eval: true
P0 = 20
r = 0.2
n_years = 20
poblacion = P0 * (1 + r)**n_years
print(f"Poblaci√≥n despu√©s de {n_years} a√±os: {poblacion:.0f} conejos")
```

---

::: {.nonincremental}


**Modelo 2: Continuo y Determin√≠stico**

**Idea**: La poblaci√≥n crece, pero est√° limitada por los recursos del entorno (una "capacidad de carga").
**Modelo**: La Ecuaci√≥n Diferencial Log√≠stica.

$$
\frac{dP}{dt} = rP(1-\frac{P}{K})
$$

Donde:

- $P$: Poblaci√≥n
- $K:$ Capacidad de Carga
- $r$: Tasa de Crecimiento

**Clasificaci√≥n:**

* Continuo: El cambio se modela en cada instante del tiempo.
* Determin√≠stico: El comportamiento est√° definido por la ecuaci√≥n.
* Mecanicista: Incluye un mecanismo (competencia por recursos, K).

:::

---

```{python}
#| echo: false
#| eval: true
#| fig-width: 6
#| fig-height: 4
#| fig-align: center

import numpy as np
import matplotlib.pyplot as plt
from scipy.integrate import odeint

# Modelo 2: Continuo y Determin√≠stico (Log√≠stico)
def logistic_model(P, t, r, K):
    return r * P * (1 - P / K)

P0 = 10
r = 0.5 
K = 150
t = np.linspace(0, 20, 100)
P_logistic = odeint(logistic_model, P0, t, args=(r, K))

plt.style.use('seaborn-v0_8-whitegrid')
fig = plt.figure(figsize=(5, 3.5))
ax = fig.add_subplot(111)
ax.plot(t, P_logistic, label='Modelo Log√≠stico Continuo', color='coral')
ax.set_title("Crecimiento Log√≠stico con Capacidad de Carga")
ax.set_xlabel("A√±os")
ax.set_ylabel("Poblaci√≥n de Conejos")
ax.axhline(y=K, color='gray', linestyle='--', label=f'Capacidad de Carga K={K}')
ax.legend()
plt.show()
```

---

::: {.nonincremental}


**Modelo 3: Discreto y Estoc√°stico**

**Idea:** El crecimiento anual no es fijo; hay a√±os buenos y malos debido a factores impredecibles (clima, enfermedades).

**Modelo:** El modelo discreto, pero con un factor de crecimiento aleatorio.

$$
P_{n+1} = (1.2 + \epsilon) \cdot P_n,\quad \epsilon \sim \mathcal{N}(0, \sigma^2)
$$


**Clasificaci√≥n:**

* Discreto: Pasos anuales.
* Estoc√°stico: Incorpora incertidumbre expl√≠citamente.
* Mecanicista (con ruido): La regla base es la misma, pero con variabilidad.

:::

---

```{python}
#| echo: false
#| eval: true
#| fig-align: center

import numpy as np
import matplotlib.pyplot as plt

# Modelo 3: Discreto y Estoc√°stico
np.random.seed(42) # Para reproducibilidad
P0 = 10
r_mean = 0.2
r_std = 0.15
n_years = 20
P_stochastic = [P0]
for _ in range(n_years):
    growth_rate = 1 + np.random.normal(r_mean, r_std)
    P_stochastic.append(P_stochastic[-1] * growth_rate)

years = np.arange(n_years + 1)
plt.style.use('seaborn-v0_8-whitegrid')
fig = plt.figure(figsize=(5, 3.5))
ax = fig.add_subplot(111)
ax.plot(years, P_stochastic, 'o-', label='Modelo Discreto Estoc√°stico', color='limegreen')
ax.set_title("Crecimiento con Incertidumbre Anual")
ax.set_xlabel("A√±os")
ax.set_ylabel("Poblaci√≥n de Conejos")
ax.legend()
plt.show()
```

---

::: {.nonincremental}

**Modelo 4: Emp√≠rico (Basado en Datos)**

Idea: No conocemos la biolog√≠a de los conejos, pero tenemos datos hist√≥ricos. Ajustamos una funci√≥n a esos datos.

**Modelo:** Una regresi√≥n (en este caso, polin√≥mica de grado 3) que minimiza el error con respecto a los datos observados.

**Clasificaci√≥n:**

* Emp√≠rico: Describe el "qu√©" (la tendencia en los datos), no el "porqu√©".
* Puede ser discreto o continuo en su formulaci√≥n.
* Puede ser determin√≠stico (la curva) o estoc√°stico (si consideramos los residuos).

:::

---

```{python}
#| echo: false
#| eval: true
#| fig-align: center

import numpy as np
import matplotlib.pyplot as plt

# Generar datos "reales" para el modelo emp√≠rico
np.random.seed(0)
years_data = np.arange(21)
true_logistic = 150 / (1 + ((150 - 10) / 10) * np.exp(-0.4 * years_data))
observed_data = true_logistic + np.random.normal(0, 10, len(years_data))

# Modelo 4: Emp√≠rico (Regresi√≥n Polin√≥mica)
coeffs = np.polyfit(years_data, observed_data, 3) # Ajuste a un polinomio de grado 3
p = np.poly1d(coeffs)
P_empirical = p(years_data)

plt.style.use('seaborn-v0_8-whitegrid')
fig = plt.figure(figsize=(5, 3.5))
ax = fig.add_subplot(111)
ax.scatter(years_data, observed_data, color='red', label='Datos Observados', zorder=5)
ax.plot(years_data, P_empirical, label='Modelo Polin√≥mico Emp√≠rico', color='purple', linestyle='-')
ax.set_title("Ajuste de un Modelo a Datos Observados")
ax.set_xlabel("A√±os")
ax.set_ylabel("Poblaci√≥n de Conejos")
ax.legend()
plt.show()

```

---

```{python}
#| echo: false
#| eval: true
#| fig-align: center

import numpy as np
import matplotlib.pyplot as plt
from scipy.integrate import odeint

# Regenerar todos los datos para el gr√°fico final
P0 = 10
n_years = 20
years = np.arange(n_years + 1)

# 1. Discreto Determin√≠stico
P_discrete = [P0]
for _ in range(n_years): P_discrete.append(P_discrete[-1] * 1.2)

# 2. Log√≠stico
t_cont = np.linspace(0, 20, 100)
P_logistic = odeint(lambda P, t: 0.5 * P * (1 - P / 150), P0, t_cont)

# 3. Estoc√°stico
np.random.seed(42)
P_stochastic = [P0]
for _ in range(n_years): P_stochastic.append(P_stochastic[-1] * (1 + np.random.normal(0.2, 0.15)))

# 4. Emp√≠rico
np.random.seed(0)
true_logistic = 150 / (1 + ((150 - 10) / 10) * np.exp(-0.4 * years))
observed_data = true_logistic + np.random.normal(0, 10, len(years))
coeffs = np.polyfit(years, observed_data, 3)
p = np.poly1d(coeffs)
P_empirical = p(years)

# Gr√°fico
plt.style.use('seaborn-v0_8-whitegrid')
fig = plt.figure(figsize=(8, 3.8))
ax = fig.add_subplot(111)

ax.plot(years, P_discrete, 'o--', label='1. Discreto (Crecimiento simple)', color='skyblue', alpha=0.8)
ax.plot(t_cont, P_logistic, label='2. Continuo (Con l√≠mites)', color='coral', linewidth=2.5)
ax.plot(years, P_stochastic, 'o-', label='3. Estoc√°stico (Con incertidumbre)', color='limegreen')
ax.plot(years, P_empirical, '--', label='4. Emp√≠rico (Ajuste a datos)', color='purple', linewidth=2.5)
ax.scatter(years, observed_data, color='red', label='Datos "Reales"', zorder=5, s=20, alpha=0.6)

ax.set_title("Cuatro Enfoques para un Mismo Problema")
ax.set_xlabel("A√±os")
ax.set_ylabel("Poblaci√≥n de Conejos")
ax.legend(fontsize='small')
ax.set_ylim(0, max(P_discrete) * 0.6)

plt.show()
```

---

Asumiendo una tasa de crecimiento base del **20%** y una poblaci√≥n inicial ($P_0$) de **20 conejos**, la predicci√≥n a 20 a√±os var√≠a dr√°sticamente seg√∫n las suposiciones del modelo:

```{python}
#| echo: false
#| eval: true
#| results: asis

import numpy as np
from scipy.integrate import odeint

# --- Par√°metros Estandarizados ---
P0 = 20
r = 0.2
n_years = 20
K = 150
r_std = 0.15
seed = 42

# --- 1. C√°lculo Discreto Determin√≠stico ---
res_discrete = P0 * (1 + r)**n_years

# --- 2. C√°lculo Log√≠stico Determin√≠stico ---
def logistic_model(P, t, r, K): return r * P * (1 - P / K)
t_eval = np.linspace(0, n_years, n_years + 1)
pob_logistic = odeint(logistic_model, P0, t_eval, args=(r, K))
res_logistic = pob_logistic[-1][0]

# --- 3. C√°lculo Discreto Estoc√°stico ---
np.random.seed(seed)
pob_stochastic = float(P0)
for _ in range(n_years):
    pob_stochastic *= (1 + np.random.normal(r, r_std))
res_stochastic = pob_stochastic

# --- 4. C√°lculo Emp√≠rico ---
np.random.seed(0)
years_data = np.arange(n_years + 1)
# Se generan datos "observados" de un proceso log√≠stico comparable
true_logistic = K / (1 + ((K - P0) / P0) * np.exp(-r * years_data))
observed_data = true_logistic + np.random.normal(0, 10, len(years_data))
# Se ajusta el modelo y se predice
coeffs = np.polyfit(years_data, observed_data, 3)
p = np.poly1d(coeffs)
res_empirical = p(n_years)

# --- Impresi√≥n de Resultados en Markdown ---
print(f"""
- Modelo Discreto-Determin√≠stico: {res_discrete:.0f} conejos
- Modelo Log√≠stico-Determin√≠stico: {res_logistic:.0f} conejos
- Modelo Discreto-Estoc√°stico: {res_stochastic:.0f} conejos (un resultado posible)
- Modelo Emp√≠rico (por ajuste): {res_empirical:.0f} conejos
""")
```

---

**Receso breve (5min)**

---

#  Secci√≥n 3, Parte I: Instalaci√≥n de Herramientas y Ejercicios


**Objetivo:** Instalar y verificar instalaci√≥n de Python y Jupyter notebooks para realizar modelamiento, simulaciones y ajustes de modelos.

---

- Si no se tiene instalado Python, la forma m√°s sencilla es hacerlo desde la distribuci√≥n Anaconda.

- Las librer√≠as necesarias son:
  * `numpy`
  * `pandas`
  * `matplotlib`
  * `scipy`

---

**Ejercicios en Python**

Notebook `code/sec3-tools.ipynb`.

---

#  Secci√≥n 3, Parte 2: El Proceso de Modelaci√≥n

**Objetivo**: 

---

**El Proceso de Modelaci√≥n es un Ciclo Iterativo**

Antes de ver los pasos, es crucial entender que la modelaci√≥n no es un proceso lineal, sino un **ciclo iterativo**.

::: {.latex}
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.55\textwidth]{figuras/world-model-relationship.png}
  \caption{Relaciones entre realidad, modelo, interpretaci√≥n.}
  \label{fig:world-model-relationship}
\end{figure}
:::

---

* Rara vez se construye un modelo perfecto al primer intento.
* El objetivo es empezar con algo simple, validarlo y **refinarlo** progresivamente.
* Cada paso informa al siguiente y, a menudo, nos obliga a regresar a un paso anterior.

---

### Paso 1: Identificaci√≥n del Problema

Todo buen modelo comienza con una **pregunta clara y bien definida**. Este es el paso m√°s importante. Si la pregunta es ambigua, el modelo ser√° in√∫til.

* **El Objetivo:** ¬øQu√© queremos lograr?
    * **Explicar:** Entender por qu√© las filas se hacen largas a mediod√≠a.
    * **Predecir:** Estimar el tiempo de espera promedio ma√±ana a las 10 am.
    * **Optimizar:** Determinar si necesitamos abrir una segunda caja para que nadie espere m√°s de 5 minutos.

* **Variables y Alcance:** ¬øQu√© mediremos y cu√°les son los l√≠mites?
    * **Variables:** Tiempo de espera, n√∫mero de clientes, tasa de servicio.
    * **Alcance:** Modelaremos una sola caja en un d√≠a laboral normal.

---

### Paso 2: Establecimiento de Suposiciones

Los modelos son simplificaciones. Las **suposiciones** son las reglas expl√≠citas de esa simplificaci√≥n y definen la base (y las limitaciones) de nuestro modelo.

* Deben ser **expl√≠citas** y **justificables**.
* Nos permiten transformar un problema complejo y "sucio" en uno matem√°tico y "limpio".
* **Ejemplo: La Fila de la Cafeter√≠a ‚òï**
    * **Llegada de clientes:** Asumimos que los clientes llegan a un ritmo constante y predecible (ej. 1 cliente cada 60 segundos). Esto nos da una tasa de llegada, $\lambda$.
    * **Tiempo de servicio:** Asumimos que el barista tarda el mismo tiempo con cada cliente (ej. 45 segundos). Esto nos da una tasa de servicio, $\mu$.
    * **Comportamiento de la fila:** Asumimos que es una sola fila, nadie se rinde y se van, y el primer cliente en llegar es el primero en ser atendido (FIFO).

---

### Paso 3: Formulaci√≥n del Modelo

Traducimos nuestras suposiciones a un lenguaje l√≥gico o matem√°tico. En este caso, no usaremos una sola ecuaci√≥n, sino un **algoritmo de simulaci√≥n** que opera paso a paso en el tiempo.

**Variables Clave del Modelo:**

* `tiempo_actual`: El reloj de nuestra simulaci√≥n (en segundos).
* `clientes_en_cola`: N√∫mero de personas esperando.
* `tiempo_para_llegada`: Contador para saber cu√°ndo llega el siguiente cliente.
* `tiempo_servicio_restante`: Contador para saber cu√°ndo el barista se desocupa.

---

**L√≥gica de la Simulaci√≥n (Pseudoc√≥digo):**

1.  Inicializar todas las variables a cero.
2.  Para cada segundo de 1 hora (3600 segundos):
    a.  Reducir en 1 los contadores de tiempo.
    b.  **¬øLleg√≥ un cliente?** Si `tiempo_para_llegada` llega a 0, a√±adir 1 a la cola y reiniciar el contador.
    c.  **¬øEl barista est√° libre?** Si `tiempo_servicio_restante` es 0 y hay gente en la cola, atender a 1 cliente (restarlo de la cola) y reiniciar el contador de servicio.
    d.  Registrar el n√∫mero de clientes en cola en este segundo.

---

**An√°lisis y Soluci√≥n**

Ahora, implementamos el algoritmo en Python para "resolver" el modelo, es decir, para ver qu√© resultados produce. 

Notebook: `code/sec3-modeling.ipynb`.

---

```{python}
#| echo: false
#| eval: true
#| fig-align: center

import numpy as np
import matplotlib.pyplot as plt

# 1. Suposiciones (par√°metros)
SEGUNDOS_LLEGADA = 60
SEGUNDOS_SERVICIO = 45
TIEMPO_SIMULACION = 3600 # 1 hora

# 2. Inicializaci√≥n
clientes_en_cola = 0
tiempo_para_llegada = SEGUNDOS_LLEGADA
tiempo_servicio_restante = 0
historial_cola = []

# 3. Ciclo de simulaci√≥n con l√≥gica corregida
for segundo_actual in range(TIEMPO_SIMULACION):
    # El tiempo avanza para el barista
    if tiempo_servicio_restante > 0:
        tiempo_servicio_restante -= 1

    # PASO 1: ¬øLleg√≥ un cliente?
    if segundo_actual >= tiempo_para_llegada:
        clientes_en_cola += 1
        tiempo_para_llegada += SEGUNDOS_LLEGADA
    
    # PASO 2: Registrar el estado de la cola *despu√©s* de las llegadas
    historial_cola.append(clientes_en_cola)
    
    # PASO 3: ¬øEl barista est√° libre para atender a alguien de la cola?
    if tiempo_servicio_restante <= 0 and clientes_en_cola > 0:
        clientes_en_cola -= 1
        tiempo_servicio_restante = SEGUNDOS_SERVICIO

# --- Visualizaci√≥n de Resultados con Gr√°fico de Pasos ---
plt.style.use('seaborn-v0_8-whitegrid')
fig, ax = plt.subplots(figsize=(6, 2.5))

# Usar plt.step para visualizar cambios discretos
ax.step(range(TIEMPO_SIMULACION), historial_cola, where='post')

ax.set_title("Evoluci√≥n de la Cola de la Cafeter√≠a (Modelo Determin√≠stico)")
ax.set_xlabel("Tiempo (segundos)")
ax.set_ylabel("Clientes en la Cola")
ax.set_yticks([0, 1]) # Fijar los ticks del eje Y a 0 y 1
ax.axhline(y=np.mean(historial_cola), color='r', linestyle='--', label=f"Promedio: {np.mean(historial_cola):.2f} clientes")
plt.legend()
# Enfocar el gr√°fico en los primeros minutos para ver el detalle
plt.xlim(0, 600)
plt.show()

print(f"Simulaci√≥n completada.")
print(f"Tama√±o m√°ximo de la cola: {max(historial_cola)} clientes.")

```
---

El resultado del modelo (la simulaci√≥n) debe ser interpretado en el contexto del problema original.

- ¬øQu√© nos dice el gr√°fico? La simulaci√≥n muestra que la cola nunca crece. Permanece en 0 o salta brevemente a 1.
- ¬øPor qu√© ocurre esto? Nuestras suposiciones iniciales lo garantizan. La tasa de servicio (Œº=1/45 clientes/seg) es mayor que la tasa de llegada (Œª=1/60 clientes/seg). El barista es m√°s r√°pido que la llegada de clientes, por lo que el sistema es estable y no se congestiona.
- Validaci√≥n: ¬øEs esto realista? No del todo. La llegada de clientes y los tiempos de servicio no son constantes. Este resultado nos lleva al siguiente paso del ciclo.

---

**Refinamiento del Modelo**

Nuestro modelo simple nos dio una primera respuesta, pero su irrealismo nos invita a mejorarlo. El ciclo iterativo de modelaci√≥n consiste en cuestionar las suposiciones y refinarlas.

- Pregunta de Refinamiento: ¬øQu√© pasar√≠a si la llegada de clientes fuera aleatoria, siguiendo una distribuci√≥n de Poisson, que es m√°s com√∫n para este tipo de fen√≥menos?
- Nueva Suposici√≥n: En lugar de un cliente cada 60 segundos, *la probabilidad de que un cliente llegue en un segundo dado es de 1/60*.
- Modificaci√≥n: Cambiamos la l√≥gica de llegada para incorporar aleatoriedad (`np.random.rand()`).

Este proceso de **cr√≠tica -> refinamiento -> nueva simulaci√≥n** es el n√∫cleo del proceso de modelaci√≥n.

---

```{python}
#| echo: false
#| eval: true
#| fig-align: center

# 1. Suposiciones (par√°metros)
# La probabilidad mantiene el mismo promedio de 1 cliente cada 60s
PROBABILIDAD_LLEGADA = 1.0 / 60.0 # 1 cliente cada 60 segundos en promedio
SEGUNDOS_SERVICIO = 45
TIEMPO_SIMULACION = 3600  # 1 hora

# 2. Inicializaci√≥n
clientes_en_cola = 0
tiempo_servicio_restante = 0
historial_cola = []

# 3. Ciclo de simulaci√≥n con l√≥gica estoc√°stica
for segundo_actual in range(TIEMPO_SIMULACION):
    if tiempo_servicio_restante > 0:
        tiempo_servicio_restante -= 1

    # PASO 1 (MODIFICADO): ¬øLleg√≥ un cliente?
    # Se genera un n√∫mero aleatorio entre 0 y 1. Si es menor que nuestra
    # probabilidad definida, consideramos que un cliente ha llegado.
    if np.random.rand() < PROBABILIDAD_LLEGADA:
        clientes_en_cola += 1

    # PASO 2: Registrar el estado de la cola
    historial_cola.append(clientes_en_cola)

    # PASO 3: ¬øEl barista est√° libre para atender?
    if tiempo_servicio_restante <= 0 and clientes_en_cola > 0:
        clientes_en_cola -= 1
        tiempo_servicio_restante = SEGUNDOS_SERVICIO

# --- Visualizaci√≥n de Resultados ---
plt.style.use('seaborn-v0_8-whitegrid')
fig, ax = plt.subplots(figsize=(10, 4))
ax.step(range(TIEMPO_SIMULACION), historial_cola, where='post')
ax.set_title("Evoluci√≥n de la Cola (Modelo Estoc√°stico)")
ax.set_xlabel("Tiempo (segundos)")
ax.set_ylabel("Clientes en la Cola")
ax.axhline(y=np.mean(historial_cola), color='r', linestyle='--',
           label=f"Promedio: {np.mean(historial_cola):.2f} clientes")
plt.legend()
plt.show()

print(f"Simulaci√≥n estoc√°stica completada.")
print(f"Tama√±o m√°ximo de la cola: {max(historial_cola)} clientes.")
```

--- 

Ahora que tenemos un modelo estoc√°stico funcional, podemos usarlo para lo que realmente sirve: experimentar con el futuro y tomar decisiones informadas.

**An√°lisis de Escenario: ¬øInvertir en una m√°quina m√°s r√°pida?**

Planteamos una pregunta de negocio concreta para guiar nuestro an√°lisis.

- **Situaci√≥n Actual:** Nuestro barista tarda **45 segundos** por cliente.
- **Propuesta:** Invertir en una m√°quina que reduce el tiempo de servicio a **30 segundos**.
- **Pregunta Clave:** ¬øC√≥mo se benefician los clientes? ¬øCu√°l es el impacto cuantificable en la longitud de la cola y el tiempo de espera?

---

**Metodolog√≠a: Simulaci√≥n de Monte Carlo**

Debido a que nuestro modelo es aleatorio, una sola simulaci√≥n no es suficiente. El resultado podr√≠a ser por pura suerte. Para obtener una estimaci√≥n confiable, realizamos un **An√°lisis de Monte Carlo**:

1.  **Encapsular la L√≥gica:** Convertimos nuestro c√≥digo de simulaci√≥n en una funci√≥n reutilizable que acepta el `tiempo_de_servicio` como par√°metro.

2.  **Ejecutar M√∫ltiples Veces:** Corremos la simulaci√≥n un n√∫mero grande de veces (ej., 100 o 1,000) para cada escenario (45s y 30s).

3.  **Promediar Resultados:** Calculamos el promedio de las m√©tricas clave (longitud m√°xima y promedio de la cola) a trav√©s de todas las ejecuciones para cada escenario.

4.  **Comparar y Decidir:** Con los promedios estables, podemos comparar de manera fiable el rendimiento de ambos sistemas y tomar una decisi√≥n basada en datos.

---

# Secci√≥n 4, Parte I: Fundamentos y Ajuste del Modelo
**Objetivo:** Introducir la intuici√≥n detr√°s de GMM y ajustar un primer modelo.

---

**K-means**

¬øQu√© es K-Means?

. . .

K-Means es uno de los algoritmos m√°s fundamentales de **aprendizaje no supervisado**. Su objetivo es simple:

. . .

> Particionar un conjunto de datos en **K** grupos (clusters) distintos y no superpuestos, donde cada punto de datos pertenece al cluster cuyo centro (centroide) es el m√°s cercano.

. . .

El algoritmo busca que los clusters sean lo m√°s **compactos** y **separados** posible, minimizando la varianza dentro de cada cluster.

---

Matem√°ticamente, el modelo K-Means postula que una agrupaci√≥n ideal es aquella que minimiza la **inercia**, tambi√©n conocida como la suma de cuadrados dentro de cada cluster. Su objetivo es resolver esta ecuaci√≥n:

$$J = \sum_{i=1}^{K} \sum_{\mathbf{x} \in C_i} ||\mathbf{x} - \boldsymbol{\mu}_i||^2$$

Donde:

* $K$ es el n√∫mero de clusters.
* $C_i$ es el conjunto de puntos en el cluster $i$.
* $\boldsymbol{\mu}_i$ es el centroide (la media) del cluster $i$.

El algoritmo iterativo que usamos es, en realidad, una t√©cnica num√©rica para encontrar una soluci√≥n a esta funci√≥n de coste. Por lo tanto, K-Means es un modelo porque **abstrae la estructura de los datos** (usando centroides) y tiene un **objetivo matem√°tico formal**.


---

**¬øC√≥mo Funciona? El Proceso Iterativo**

K-Means encuentra los clusters a trav√©s de un proceso iterativo de dos pasos:

1.  **Paso de Asignaci√≥n**: A cada punto de datos se le asigna el centroide m√°s cercano.

2.  **Paso de Actualizaci√≥n**: Se recalcula la posici√≥n de cada centroide, movi√©ndolo al centro (promedio) de todos los puntos de datos que le fueron asignados.

Estos dos pasos se repiten hasta que los centroides dejan de moverse y las asignaciones de los clusters se estabilizan.

---

**¬øPor qu√© GMM?**

K-Means es una excelente herramienta, pero tiene supuestos r√≠gidos que no siempre se cumplen.

. . .

-   **Asignaci√≥n "Dura"**: Un punto pertenece a un cluster o a otro, no hay incertidumbre. ¬øQu√© pasa con los puntos en las fronteras?

-   **Clusters Esf√©ricos**: K-Means asume que los clusters tienen una forma circular y un tama√±o similar, ya que solo optimiza la distancia al centroide.


. . .

> Necesitamos un modelo m√°s flexible que pueda capturar clusters de diferentes formas y orientaciones, y que adem√°s nos diga qu√© tan "seguro" est√° de la asignaci√≥n de cada punto.

---

**Intuici√≥n de GMM:**

Imaginar que los datos no provienen de una sola fuente, sino de varias fuentes superpuestas.

. . .

**Gaussian Mixture Models (GMM)** asume que los datos son una combinaci√≥n de varias distribuciones Normales (Gaussianas), cada una con su propio:

-   **Centro** (Media): ¬øD√≥nde est√° el cluster?
-   **Forma y Orientaci√≥n** (Covarianza): ¬øEs circular, el√≠ptico, alargado?
-   **Tama√±o** (Peso): ¬øQu√© proporci√≥n de los datos pertenece a este cluster?

---

GMM un modelo de **asignaci√≥n "suave"**: en lugar de una etiqueta, cada punto de datos obtiene una **probabilidad** de pertenecer a cada uno de los clusters dada por:

$$
f(x) = \sum_{k=1}^{K} \pi_k \mathcal{N}(x | \mu_k, \Sigma_k)
$$

- $x$ es un dato de $D$ dimensiones.
- $\pi_k$ es el coeficiente de mezcla para la $k$-√©sima componente Gaussiana, con $0 \leq \pi_k \leq 1$ y $\sum_{k=1}^{K} \pi_k = 1$.
- $\mathcal{N}(x | \mu_k, \Sigma_k)$ es la distribuci√≥n Gaussiana de $D$ dimensiones con vector de medias $\mu_k$ y matriz de covarianza $\Sigma_k$.

---

¬øPor qu√© "Mezcla Gaussiana"?

| Caracter√≠stica | K-Means (Modelo Geom√©trico) | GMM (Modelo Probabil√≠stico) |
| :--- | :--- | :--- |
| **Suposici√≥n Clave** | Los datos forman c√∫mulos esf√©ricos. | Los datos son una **mezcla** de varias distribuciones **Gaussianas**. |
| **Par√°metros del Modelo** | Un conjunto de $K$ centroides: $\{\boldsymbol{\mu}_1, ..., \boldsymbol{\mu}_K\}$. | Un conjunto de $K$ tripletas de par√°metros: $\{(\boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k, \pi_k)\}_{k=1}^K$ <br> (Media, Covarianza y Peso). |
| **Resultado** | Asignaci√≥n "dura" a un cluster. | **Probabilidad** de pertenencia a cada cluster. |

---

- K-Means tiene una visi√≥n **geom√©trica**
- GMM tiene una visi√≥n **generativa**: asume que los datos fueron *generados* por una combinaci√≥n de diferentes procesos (las gaussianas). 
- Por eso es un modelo probabil√≠stico mucho m√°s rico que no solo agrupa, sino que intenta describir la **distribuci√≥n de probabilidad** de la que provienen los datos.

---
¬øC√≥mo encuentra el modelo los par√°metros (centro, forma, tama√±o) de estas gaussianas?

. . .

El principio rector es la **Estimaci√≥n por M√°xima Verosimilitud** (*Maximum Likelihood Estimation* o MLE).

-   **La Pregunta Clave**: De todas las combinaciones posibles de gaussianas, ¬øcu√°l es la que con **mayor probabilidad** pudo haber generado los datos que observamos?


---

**Proceso de MLE**

El objetivo de MLE es encontrar el valor del par√°metro de un modelo ($\theta$) que hace que nuestros datos observados ($\mathbf{x}$) sean **lo m√°s probables posible**. Para modelos simples, podemos encontrar esta soluci√≥n anal√≠ticamente.

---

Pensemos en el caso de lanzar una moneda 10 veces y obtener 7 caras. Queremos estimar $p$, la probabilidad de que salga cara.

. . .

1.  **Definir la Funci√≥n de Verosimilitud ($\mathcal{L}(\theta|\mathbf{x})$)**
    -   Es una funci√≥n que nos dice qu√© tan probables son nuestros datos para un valor espec√≠fico del par√°metro. Para nuestro ejemplo, es la funci√≥n de masa de probabilidad binomial.
    
    $$\mathcal{L}(p|k=7, n=10) = \binom{10}{7} p^7 (1-p)^3$$

2.  **Simplificar con Log-Verosimilitud ($\ln \mathcal{L}$)**
    -   Maximizar $\mathcal{L}$ es lo mismo que maximizar $\ln \mathcal{L}$. El logaritmo convierte productos en sumas, lo que facilita enormemente la derivaci√≥n.
    
    $$\ln \mathcal{L} = \ln\left(\binom{10}{7}\right) + 7\ln(p) + 3\ln(1-p)$$

---

3.  **Derivar e Igualar a Cero (Condici√≥n de Primer Orden)**
    -   Para encontrar el m√°ximo de la funci√≥n, buscamos el punto donde su pendiente es cero.
    
    $$\frac{d \ln \mathcal{L}}{dp} = \frac{7}{p} - \frac{3}{1-p} = 0$$

4.  **Resolver para el Par√°metro ($\hat{\theta}_{MLE}$)**
    -   Al resolver la ecuaci√≥n, encontramos el valor del par√°metro que maximiza la verosimilitud.
    
    $$7(1-p) = 3p \implies 7 - 7p = 3p \implies 10p = 7 \implies \hat{p}_{MLE} = 0.7$$

---

> **El Problema:** Para modelos complejos como GMM, la derivada de la log-verosimilitud es demasiado complicada para resolverla anal√≠ticamente. Aqu√≠ es donde entra la **optimizaci√≥n num√©rica**.

$$
\begin{aligned}
& \underset{\{\pi_k, \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k\}_{k=1}^K}{\text{maximizar}}
& & \sum_{i=1}^{N} \ln \left( \sum_{k=1}^{K} \pi_k \mathcal{N}(\mathbf{x}_i | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k) \right) \\
& \text{s.a.}
& & \sum_{k=1}^{K} \pi_k = 1 \\
& & & \pi_k \ge 0, \quad \forall k \\
& & & \boldsymbol{\Sigma}_k \text{ es positiva semidefinida}, \quad \forall k
\end{aligned}
$$

---

Si $D=1$ y $K=2$, y si volvemos negativa $\ln \mathcal{L}$, tenemos:

$$
\begin{aligned}
& \underset{\mu_1, \mu_2, \sigma_1, \sigma_2, \pi_1}{\text{minimizar}}
& & -\sum_{i=1}^{N} \ln \left( \pi_1 \mathcal{N}(x_i | \mu_1, \sigma_1^2) + (1-\pi_1) \mathcal{N}(x_i | \mu_2, \sigma_2^2) \right) \\
& \text{s.a.}
& & 0 \le \pi_1 \le 1 \\
& & & \sigma_1 > 0, \quad \sigma_2 > 0
\end{aligned}
$$

Notebook: `code/sec4-gmm.ipynb`.

---

**Actividad (30min):**

Imagina que somos un equipo de control de calidad y hemos probado 150 unidades de un nuevo componente electr√≥nico hasta que fallan. Hemos registrado el tiempo de vida de cada uno en horas. Queremos modelar esta distribuci√≥n para poder hacer predicciones, como estimar la vida media del componente o la probabilidad de que falle antes de cierto tiempo.

Los datos podr√≠an ser los tiempos de falla y no siguen una distribuci√≥n normal simple.

---

::: {.nonincremental}

El Modelo: La Distribuci√≥n de Weibull

La distribuci√≥n de Weibull es extremadamente flexible y se define por dos par√°metros:

  * $k$ (par√°metro de **forma**): Describe el modo de falla.
      * $k < 1$: La tasa de falla disminuye con el tiempo (fallas infantiles).
      * $k = 1$: La tasa de falla es constante (fallas aleatorias, se reduce a la dist. exponencial).
      * $k > 1$: La tasa de falla aumenta con el tiempo (fallas por desgaste).
  * $\lambda$ (par√°metro de **escala**): Representa la "vida caracter√≠stica" del componente.

Su funci√≥n de densidad de probabilidad (PDF) es:
$$f(x; k, \lambda) = \frac{k}{\lambda} \left(\frac{x}{\lambda}\right)^{k-1} e^{-(x/\lambda)^k} \quad \text{para } x \ge 0$$

Nuestro objetivo es encontrar los valores de $k$ y $\lambda$ que mejor se ajustan a nuestros datos observados.

:::

---

Usa los datos `data\failure-times.csv`.

El objetivo es minimizar la siguiente funci√≥n $\ell \ell$ (simplificada ya de la pdf).


$$
\ell \ell^*(k, \lambda | \mathbf{x}) = - \sum_{i=1}^{N} \left[ \ln(k) - \ln(\lambda) + (k-1)(\ln(x_i) - \ln(\lambda)) - \left(\frac{x_i}{\lambda}\right)^k \right]
$$

---
**Evaluaci√≥n del taller**

[Link al form](https://forms.office.com/Pages/ResponsePage.aspx?id=8kgDb5jkyUWE9MbYHc_9_rFBhZChN8RMkFFLzJxm66ZUQ0NTVVU0VDEyVk5MU0dFU0owOVkxTFFYOSQlQCN0PWcu)

\centering\includegraphics[width=0.42\textwidth]{figuras/qr-form.jpg}